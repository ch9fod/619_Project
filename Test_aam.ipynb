{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import menpo.io as mio\n",
    "from menpo.visualize import print_progress\n",
    "from menpo.landmark import labeller, face_ibug_68_to_face_ibug_68_trimesh\n",
    "from menpowidgets import visualize_images\n",
    "from pathlib import Path\n",
    "\n",
    "path_to_images = 'C:\\\\Users\\\\ch9fod\\\\Documents\\\\lfpw\\\\trainset'\n",
    "training_images = []\n",
    "for img in print_progress(mio.import_images(path_to_images, verbose=True)):\n",
    "    # convert to greyscale\n",
    "    if img.n_channels == 3:\n",
    "        img = img.as_greyscale()\n",
    "    # crop to landmarks bounding box with an extra 20% padding\n",
    "    img = img.crop_to_landmarks_proportion(0.2)\n",
    "    # rescale image if its diagonal is bigger than 400 pixels\n",
    "    d = img.diagonal()\n",
    "    if d > 400:\n",
    "        img = img.rescale(400.0 / d)\n",
    "    # define a TriMesh which will be useful for Piecewise Affine Warp of HolisticAAM\n",
    "    labeller(img, 'PTS', face_ibug_68_to_face_ibug_68_trimesh)\n",
    "    # append to list\n",
    "    training_images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from menpofit.aam import HolisticAAM\n",
    "from menpo.feature import fast_dsift\n",
    "\n",
    "# build AAM\n",
    "aam = HolisticAAM(\n",
    "    training_images,\n",
    "    group='face_ibug_68_trimesh',\n",
    "    verbose=True,\n",
    "    holistic_features=fast_dsift, \n",
    "    diagonal=120, \n",
    "    scales=(0.5, 1.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from menpofit.aam import LucasKanadeAAMFitter\n",
    "\n",
    "fitter = LucasKanadeAAMFitter(aam, n_shape=0.9, n_appearance=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_lfpw = Path('C:\\\\Users\\\\ch9fod\\\\Documents\\\\lfpw\\\\')\n",
    "\n",
    "# load test and failed images\n",
    "test_images = []\n",
    "bboxes = []\n",
    "for i in mio.import_images(path_to_lfpw / 'MySet', max_images=12, verbose=True):\n",
    "    # crop image\n",
    "    i = i.crop_to_landmarks_proportion(0.2)\n",
    "    # convert it to grayscale if needed\n",
    "    if i.n_channels == 3:\n",
    "        i = i.as_greyscale(mode='luminosity')\n",
    "    # append it to the list\n",
    "    test_images.append(i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from menpofit.fitter import noisy_shape_from_bounding_box\n",
    "\n",
    "fitting_results = []\n",
    "\n",
    "# fit images\n",
    "for i in test_images:\n",
    "    # obtain ground truth (original) landmarks\n",
    "    gt_s = i.landmarks['LJSON'].lms\n",
    "    \n",
    "    # generate initialization shape\n",
    "    initial_s = noisy_shape_from_bounding_box(gt_s, gt_s.bounding_box())\n",
    "    \n",
    "    # fit image\n",
    "    fr = fitter.fit_from_shape(i, initial_s, gt_shape=gt_s)\n",
    "    fitting_results.append(fr)\n",
    "    \n",
    "    # print fitting error\n",
    "    #print(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from menpowidgets import visualize_fitting_result\n",
    "\n",
    "visualize_fitting_result(fitting_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#comments\n",
    "'''\n",
    "aam.view_shape_models_widget()\n",
    "aam.view_appearance_models_widget()\n",
    "aam.view_aam_widget()\n",
    "\n",
    "%matplotlib inline\n",
    "from menpowidgets import visualize_images\n",
    "visualize_images(training_images)\n",
    "\n",
    "from menpofit.aam import PatchAAM\n",
    "from menpo.feature import fast_dsift\n",
    "\n",
    "patch_aam = PatchAAM(training_images, group='PTS', patch_shape=[(15, 15), (23, 23)],\n",
    "                     diagonal=150, scales=(0.5, 1.0), holistic_features=fast_dsift,\n",
    "                     max_shape_components=20, max_appearance_components=150,\n",
    "                     verbose=True)                   \n",
    "\n",
    "from menpofit.aam import HolisticAAM\n",
    "from menpo.feature import fast_dsift\n",
    "\n",
    "aam = HolisticAAM(training_images, group='face_ibug_68_trimesh', diagonal=150,\n",
    "                  scales=(0.5, 1.0), holistic_features=fast_dsift, verbose=True,\n",
    "                  max_shape_components=20, max_appearance_components=150)\n",
    "                  \n",
    "fitter = LucasKanadeAAMFitter(aam, lk_algorithm_cls=WibergInverseCompositional,\n",
    "                              n_shape=[5, 20], n_appearance=[30, 150])                  \n",
    "                  \n",
    "result.view(render_initial_shape=True)\n",
    "result.view_iterations()\n",
    "result.view_widget()\n",
    "                  \n",
    "image.view()   \n",
    "image = image.crop_to_landmarks_proportion(0.5)\n",
    "\n",
    "# TEST!!!\n",
    "#len(bboxes)\n",
    "#print(test_images[0].landmarks)\n",
    "#image.landmarks.group_labels[0]\n",
    "training_images[0].landmarks.group_labels[0]\n",
    "\n",
    "visualize_images(test_images)\n",
    "\n",
    "# View\n",
    "#if len(bboxes) > 0:\n",
    "#    image.view_landmarks(group='bbox_0', line_colour='red',\n",
    "#                         render_markers=False, line_width=4);\n",
    "\n",
    "# Detect\n",
    "#bboxes = detect(image)\n",
    "#print(\"{} detected faces.\".format(len(bboxes)))\n",
    "\n",
    "# View\n",
    "#if len(bboxes) > 0:\n",
    "#    image.view_landmarks(group='dlib_0', line_colour='red',\n",
    "#                         render_markers=False, line_width=4);\n",
    "\n",
    "test_images[0].view_landmarks(group='bbox_0', line_colour='red',\n",
    "                     render_markers=False, line_width=4);\n",
    "\n",
    "#from menpodetect import load_dlib_frontal_face_detector\n",
    "\n",
    "# Load detector\n",
    "#detect = load_dlib_frontal_face_detector()\n",
    "\n",
    "from menpofit.aam import LucasKanadeAAMFitter, WibergInverseCompositional\n",
    "fitter = LucasKanadeAAMFitter(aam, lk_algorithm_cls=WibergInverseCompositional,\n",
    "                              n_shape=[5, 20], n_appearance=[30, 150])\n",
    "                              \n",
    "image = mio.import_image(path_to_lfpw / 'Jorge1.jpg')\n",
    "image = image.as_greyscale()\n",
    "\n",
    "from menpodetect import load_dlib_frontal_face_detector\n",
    "\n",
    "# Load detector\n",
    "detect = load_dlib_frontal_face_detector()\n",
    "\n",
    "#bboxes = detect(image)\n",
    "bboxes = detect(image, group_prefix='bbox')\n",
    "\n",
    "print(\"{} detected faces.\".format(len(bboxes)))            \n",
    "\n",
    "# fiting images\n",
    "#for i in test_images:\n",
    "    # fit image\n",
    "#    fr = fitter.fit_from_bb(i,\n",
    "#                            bboxes[index],\n",
    "#                            max_iters=[15, 5],\n",
    "#                            gt_shape=None)\n",
    "#    index += 1\n",
    "#    fitting_results.append(fr)\n",
    "\n",
    "# print result\n",
    "#print(result)\n",
    "                     \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
